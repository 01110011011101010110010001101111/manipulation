<!DOCTYPE html>

<html>

  <head>
    <title>Robotic Manipulation: Force Control</title>
    <meta name="Robotic Manipulation: Force Control" content="text/html; charset=utf-8;" />
    <link rel="canonical" href="http://manipulation.csail.mit.edu/force.html" />

    <script src="https://hypothes.is/embed.js" async></script>
    <script type="text/javascript" src="htmlbook/book.js"></script>

    <script src="htmlbook/mathjax-config.js" defer></script> 
    <script type="text/javascript" id="MathJax-script" defer
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <script>window.MathJax || document.write('<script type="text/javascript" src="htmlbook/MathJax/es5/tex-chtml.js" defer><\/script>')</script>

    <link rel="stylesheet" href="htmlbook/highlight/styles/default.css">
    <script src="htmlbook/highlight/highlight.pack.js"></script> <!-- http://highlightjs.readthedocs.io/en/latest/css-classes-reference.html#language-names-and-aliases -->
    <script>hljs.initHighlightingOnLoad();</script>

    <link rel="stylesheet" type="text/css" href="htmlbook/book.css" />
  </head>

<body onload="loadChapter('manipulation');">

<div data-type="titlepage">
  <header>
    <h1><a href="index.html" style="text-decoration:none;">Robotic Manipulation</a></h1>
    <p data-type="subtitle">Perception, Planning, and Control</p> 
    <p style="font-size: 18px;"><a href="http://people.csail.mit.edu/russt/">Russ Tedrake</a></p>
    <p style="font-size: 14px; text-align: right;"> 
      &copy; Russ Tedrake, 2020<br/>
      Last modified <span id="last_modified"></span>.</br>
      <script>
      var d = new Date(document.lastModified);
      document.getElementById("last_modified").innerHTML = d.getFullYear() + "-" + (d.getMonth()+1) + "-" + d.getDate();</script>
      <a href="misc.html">How to cite these notes, use annotations, and give feedback.</a><br/>
    </p>
  </header>
</div>

<p><b>Note:</b> These are working notes used for <a
href="http://manipulation.csail.mit.edu/Fall2020/">a course being taught
at MIT</a>. They will be updated throughout the Fall 2020 semester.  <!-- <a 
href="https://www.youtube.com/channel/UChfUOAhz7ynELF-s_1LPpWg">Lecture  videos are available on YouTube</a>.--></p> 

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter" href=segmentation.html>Previous Chapter</a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=drake.html>Next Chapter</a></td>
</tr></table>


<!-- EVERYTHING ABOVE THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->
<chapter style="counter-reset: chapter 6"><h1>Force Control</h1>
  <a style="float:right; margin-top:-80px;" target="force" href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/force.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open Corresponding Notebook In Colab"/></a>
  <div style="clear:right;"></div>

  <p>Over the last few chapters, we've developed a great initial toolkit for
  perceiving objects (or piles of objects) in a scene, planning grasps, and
  moving the arm to grasp.  But there is a lot more to manipulation than
  grasping!</p>

  <p>In fact, the signs have already been there if you were paying close
  attention.  I'm sure that you noticed image number 9954 in my clutter
  segmentation dataset.  Good old <code>09954.png</code>. Just in case you
  happened to miss it, here it is again.</p>

  <figure><img style="width:60%" src="data/09954.png"/></figure>

  <p>I don't know how many of the other 9999 random scenes that we generated are
  going to have this problem, but 9954 makes it nice and clear.  How in the
  world are we going to pick up that "Cheez-it" cracker box with our
  two-fingered gripper?  (I know there are a few of you out there thinking about
  how easy that scene is for your suction gripper, but suction alone isn't going
  to solve all of our problems either.)</p>

  <figure><iframe width="560" height="315"
  src="https://www.youtube.com/embed/XqRczI4Fepk?mute=1&rel=0" frameborder="0"
  allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope;
  picture-in-picture" allowfullscreen></iframe><figcaption>Just for fun, I asked
  my daughter to try a similar task with the "two-fingered gripper" I scrounged
  from my kitchen. How are we to program something like
  that!</figcaption></figure>

  <p>The term <i>nonprehensile manipulation</i> means "manipulation without
  grasping", and humans do it often.  It is easy to appreciate this fact when we
  think about pushing an object that is too big to grasp (e.g. an office chair).
  But if you pay close attention, you will see that humans make use of
  strategies like sliding and environmental contact often, even when they are
  grasping. These strategies just come to the forefront in non-grasping
  manipulation.</p>

  <p>As we build up our toolkit for prehensile and nonprehensile manipulation,
  one of the things that is missing from our discussion so far, which has been
  predominantly kinematic, has been thinking about forces.  This chapter aims to
  begin that discussion.  By the end, I hope you'll agree that we have a pretty
  satisfying way to flip up that box!</p>

  <section><h1>A simple model</h1>
  
    <p>As always in our battle against complexity, I want to find a setup that
    is as simple as possible (but no simpler)!  Here is my proposal for the
    box-flipping example.  First, I will restrict all motion to a 2D plane; this
    allows me to chop off two sides of the bin (for you to easily see inside),
    but also drops the number of degrees of freedom we have to consider.  In
    particular, we can avoid the quaternion floating base coordinates, by adding
    a <code>PlanarJoint</code> to the box.  Instead of using a complete gripper,
    let's start even simpler and just use a "point finger".  I've visualized it
    as a small sphere, and modeled two control inputs as providing force
    directly on the $x$ and $z$ coordinates of the point mass.</p>

    <figure><img style="width:60%"
    src="data/point_finger_cracker_box.png"/><figcaption>The simple model: a
    point finger, a cracker box, and the bin all in 2D.  The green arrows are
    the contact forces.</figcaption></figure>

    <p>Even in this simple model, and throughout the discussions in this
    chapter, we will have two dynamic models that we care about.  The first is
    the full dynamic model used for simulation: it contains the finger, the box,
    and the bin, and has a total of 5 degrees of freedom ($x, z, \theta$ for the
    box and $x, z$ for the finger).  The second is the robot model used for
    designing the controllers: this model has just the two degrees of freedom of
    the finger, and experiences unmodelled contact forces.  By design, the
    equations of this second model are particularly simple: $$\begin{bmatrix}m &
    0 \\ 0 & m \end{bmatrix} \dot{v} = m \begin{bmatrix}\ddot{x} \\ \ddot{z}
    \end{bmatrix} = -mg + \begin{bmatrix} u_x \\ u_z \end{bmatrix} + f^c,$$
    where $m$ is the mass, $g$ is the gravity vector, $u$ is the control input
    vector, and $f^c$ is the contact force.  Notably absent is the contact
    Jacobian which normally pre-multiplies the contact forces $\sum_i J_i^T
    f^{c_i};$ in the case of a point finger this Jacobian is always the identity
    matrix, and there is only one point at which contact can be made, so there
    is no meaningful reason to distinguish between multiple forces.</p>

    <todo>Add Jiaji's video?</todo>
    <todo>Check yourself: can the finger move the box?  (only if the coefficient of friction is bigger).</todo>

    <subsection><h1>(Direct) force control</h1>

      <p>Almost always, we implement a low-level controller that converts some
      more intuitive command interface down into the generalized force inputs on
      the robot.  In the case of direct force control, the abstraction that we
      want is to be able to directly "control" the contact forces.  (In the
      general case, we must specify the contact location to provide this
      interface; again the point finger allows us to ignore that detail for the
      moment).</p>
      
      <div>
        <script type="text/javascript">
        var force_control = { "name": "ForceControl", 
          "input_ports" : ["desired_contact_force", "robot_state", "robot_accelerations OR &nbsp; &nbsp; &nbsp;<br/> measured_contact_force"],
          "output_ports" : ["robot_actuation"]
          };
        document.write(system_html(force_control));
        </script>
      </div>

      <p>Let us assume that the robot is already in contact.  What information
      do we need to regulate the contact forces?  Certainly we need the desired
      contact force, $f^{c_d}$.  In general, we will need the robot's state
      (though in the immediate example, the dynamics of our point mass are not
      state dependent).  But we also need to either (1) measure the robot
      accelerations (which we've tried to avoid), (2) assume the robot
      accelerations are zero, or (3) provide a measurement of the contact force
      so that we can regulate it with feedback.</p>
      
      <p>Assuming that the accelerations are (nearly) zero is not a horrible
      assumption (if we are already in contact) for most manipulation tasks,
      where the movements are relatively slow.  Let's assume it for now, and
      revisit the assumption later.  In this case, our equations of motion
      reduce to $$f^c = mg - u.$$  Our force controller implementation can be as
      simple as $u = -mg - f^{c_d}.$  This assumes only that we know the mass of
      the robot.</p>

      <p>What happens when the robot is not in contact?  In this case, we cannot
      reasonably ignore the accelerations, and applying the same control results
      in $m\dot{v} = - f^{c_d}.$  That's not all bad.  In fact, it's one of the
      defining features of force control that makes it very appealing.  When you
      specify a desired force and don't get it, the result is accelerating the
      contact point in the (opposite) direction of the desired force.  In
      practice, this (locally) tends to bring you into contact when you are not
      in contact.</p>

      <example><h1>Commanding a constant force</h1>

        <p>Let's see what happens when we run a full simulation which includes
        not only the non-contact case and the contact case, but also the
        transition between the two (which involves collision dynamics).  I'll
        start the point finger next to the box, and apply a constant force
        command requesting to get a horizontal contact force from the box.  I've
        drawn the $x$ trajectory of the finger for different (constant) contact
        force commands.</p>

        <figure><img style="margin-top:-20px; width:70%"
        src="data/constant_force_box.svg"><figcaption>This is a plot of the
        horizontal position of the finger as a function of time, given different
        constant desired force commands.</figcaption></figure>
        
        <p>For all strictly positive desired force commands,
        the finger will accelerate at a constant rate until it collides with the
        box (at $x=0.089$).  For small $f^{c_d}$, the box barely moves.  For an
        intermediate range of $f^{c_d}$, the collision with the box is enough to
        start it moving, but friction eventually brings the box and therefore
        also the finger to rest.  For large values, the finger will keep pushing
        the box until it runs into the far wall.</p>

        <p><a target="force"
          href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/force.ipynb#scrollTo=1B0hQuLQZMD0"><img
          src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
          </p>
      
      </example>

      <p>Consider the consequences of this behavior.  By commanding force, we
      can write a controller that will come into a nice contact with the box
      with essentially no information about the geometry of the box (we just
      need enough perception to start our finger in a location for which a
      straight-line approach will reach the box).</p>

      <p>This is one of the reasons that researchers working on legged robots
      also like force control.  On a force-capable walking robot, we might mimic
      position control during the "swing phase", to get our foot approximately
      where we are hoping to step.  But then we switch to a force control mode
      to actually set the foot down on the ground.  This can significantly
      reduce the requirements for accurate sensing of the terrain.</p>

    </subsection>

    <subsection><h1>A force-based "flip-up" strategy</h1>

      <p>Here is my proposal for a simple strategy for flipping up the box. Once
      in contact, we will use the contact force from the finger to apply a
      moment around the bottom left corner of the box to generate the rotation.
      But we'll add constraints to the forces that we apply so that the bottom
      corner does not slip. </p>

      <figure><img style="margin-top:-20px; width:60%" src="data/force_flip_up.png"><figcaption>Flipping the box.  <a href="data/force_flip_up.html">Click here</a> for an animation of the controller we'll write in the example below.  But it's worth running the code, where you can see the contact force visualization, too!</figcaption></figure>

      <p>These conditions are very natural to express in terms of forces.  And
      once again, we can implement this strategy with very little information
      about the box.  The position of the finger will evolve naturally as we
      apply the contact forces.  It's harder for me to imagine a how to write an
      equally robust strategy using a (high-gain) position-controller finger; it
      would likely require many more assumptions about the geometry (and
      possibly the mass) of the box.</p>

      <example><h1>A force-based flip-up strategy</h1>
      
        <p>Let's encode the textual description above.  The friction cone
        provides (linear inequality) constraints on the forces we want to apply.
        Within those constraints, we would like to rotate up the box.
        Constrained least-squares is as natural a formulation for this as any!
        Here is one version: \begin{align*}\min_{f^C_W} \quad& \left|
        f^{C}_{C_x} - \text{PID}(\theta_d, \theta) \right|^2,\\ \subjto \quad &
        |f^C_{W_x}| \le \hat\mu_A (\hat{m}g -
        f^C_{W_z}), \\  & f^C_{C_z} \ge 0,
        \qquad |f^C_{C_x}| \le \hat\mu_C f^C_{C_z}, \\ \text{with} \quad &
        {}^WR^C(\theta) = \begin{bmatrix} -\sin\theta & -\cos\theta \\
        \cos\theta & -\sin\theta \end{bmatrix}.\end{align*} I've used
        $\text{PID}$ here as shorthand for a simple
        proportional-integral-derivative term. Implementing this strategy
        assumes:
        <ul style="margin-top:-10px; margin-bottom:5px"><li>We have some
        approximation, $\hat\theta$, for the orientation of the box.  We could
        obtain this from a point cloud normal estimation, or even from tracking
        the path of the fingers.</li>
        <li>We have conservative estimates of the coefficients of static
        friction between the wall and the box, $\hat\mu^A$, and between the
        finger and the box, $\hat\mu^C$, as well as the box mass, $\hat{m}.$
        (You should experiment and decide for yourself whether these estimates can be loose).</li>
        <li>We assume that $\theta_d(t)$ changes slowly (in particular, that the
        box accelerations are small), so that we can mostly ignore the unknown
        inertial terms from the box .</li>
<!---        
        <li>We assume that the finger makes contact roughly near the top of the
        box, but there is no other dependency on the size of the box.</li>
        -->        
        </ul> Apart from the finger making some contact, there are no other
        assumptions about the shape of the box!</p>

        <p><a target="force"
          href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/force.ipynb#scrollTo=VBc7zDKlElKu"><img
          src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
          </p>

        <p>To understand this controller, let's break down the dynamics of the
        task.</p>  
        
        <p>Once the box has rotated up off the bin bottom, the only forces on
        the box are the gravitational force, the force that the bin applies on
        the box corner, call it $f^A$, and the contact force, $f^C$, that the
        finger applies on the box.  By convention, the contact frames $A$ and
        $C$ have the $z$ axis aligned with the contact normal (pointing into the
        box).  Remember the contact geometry we use for the cracker box has
        small spheres in the corners; so both of these contacts are "sphere on
        box", with the box normals defining the contact normals (e.g. the $x$
        axis is aligned with the wall of the box), and ${}^WR^A = I$.  The
        friction cone constraints are: \begin{gather*}f^A_{W_z} \ge
        0, \qquad |f^A_{W_x}| \le \mu^A f^A_{W_z}, \\ f^C_{C_z}
        \ge 0, \qquad |f^C_{C_x}| \le \mu^C f^C_{C_z}.\end{gather*}  The
        orientation of frame $C$ is a function of the box orientation,
        ${}^WR^C(\theta)$, and is written above.</p>

        <todo>Add diagrams for the frames</todo>

        <p>The dynamics of the box can be written as \begin{gather*} m\ddot{x} =
        f^A_{W_x} + f^C_{W_x} \\ m \ddot{z} = f^A_{W_z} + f^C_{W_z} - mg \\
        I\ddot\theta = ^Ap^{CM}_W \times \begin{bmatrix} 0 \\ -mg\end{bmatrix} +
        {}^Ap^C_W \times f^C_W, \end{gather*} where $I$ is the moment of inertia
        of the box taken around the top corner, and $p^{CM}$ is the position of
        the center of mass.  We don't want our controller to depend on most of
        these parameters, but it helps to understand them!  If we move slowly
        (the velocities and accelerations are nearly zero), then we can write
        $$f^A_{W_x} = -f^C_{W_x}, \qquad f^A_{W_z} = mg - f^C_{W_z}.$$ Taken
        together, the friction cone constraints on the bin imply the following
        constraints on our finger contact: $$|f^C_{W_x}| \le \mu_A (mg -
        f^C_{W_z}).$$  Note that the <a
        href="http://underactuated.mit.edu/multibody.html#bilateral">full
        dynamic derivation</a> is not too much harder; I did it on paper by
        writing ${}^{CM}p^A = [-\frac{h}{2}, -\frac{w}{2}]^T,$ with the height,
        $h$, and width, $w$ of the box. Then one can write the no-slip at the
        bin constraint as $\phi(q) = {}^{CM}p^A_{W_x} = \text{constant}$ which
        implies that $\ddot{\phi} = 0,$ which gives the full expression for
        $f^A_{W_x}$ (as long as we're in the friction cone).</p>

        <p>Now here's a nice approximation.  By choosing to make contact near
        the bottom of the box (since we know where the bin is), we can
        approximate $${}^Ap^{C}_W \times f^C_W \approx -{}^Ap^C_{C_z}
        f^C_{C_x}.$$  In words, the moment produce by the finger contact is
        approximately the tangential force on the box (times the width of the
        box).  I therefore claim that choosing $$f^{C_d}_{C_x} =
        \text{PID}(\theta_d, \theta),$$ is a good strategy for regulating the
        orientation of the box.  It does not assume we know the box geometry nor
        inertial properties.</p>

        <p>That's a lot of details, but all to justify a very simple and robust
        controller.</p>

        <todo>Generate random boxes.</todo>

      </example>

      <p>We have multiple controllers in this example.  The first is the
      low-level force controller that takes a desired contact force and sends
      commands to the robot to attempt to regulate this force.  The second is
      the higher-level controller that is looking at the orientation of the box
      and deciding which forces to request from the low-level controller.</p>

      <p>Please also understand that this is not some unique or optimal strategy
      for box flipping.  I'm simply trying to demonstrate that sometimes
      controllers which might be difficult to express otherwise can easily be
      expressed in terms of forces!</p>

    </subsection>

    <subsection><h1>Indirect force control (impedance and admittance)</h1>

      <p>Expressing our goals in terms of force worked well for my simple example.  But expressing goals only in terms of force can be difficult.  Sometimes we would like to mix position-control objectives with force-control objectives.</p>

      <p>Add a PD controller to the finger.  In joint control, we set the gains high and try to cancel out the unknown transmission dynamics.  Here, we think of setting the gains relatively low, and think of it as programming the mechanical response to disturbances.  Make our robot look like a spring-damper system at the point of contact.</p>

      <p>Impedance control: apply torques to cancel... cite Neville.</p>
    
      <p>We can still program the response if we have a position-controlled robot with a force-torque sensor.  We measure the force and command a new position.  This is called <i>admittance control</i>.</p>

    </subsection>

    <subsection><h1>An impedance-based "flip-up" strategy</h1>
    
    </subsection>

    <subsection><h1>Hybrid control</h1>
    
    </subsection>

  </section>

  <section><h1>Peg in hole</h1>

    <p>Call-out to the classic great example for force control.  Remote-centered
    compliance...</p>
  
    <p>Also for opening doors, tool use, ...</p>
  </section>

  <section><h1>Force control with the arm</h1>

    <p>I think that using the floating finger/gripper is a good way to
    understand the main concepts of force control without the details.  But now
    it's time to actually implement those strategies using joint commands that
    we can send to the arm.</p>

    <subsection><h1>Direct Force Control</h1>

    </subsection>

    <subsection><h1>Impedance and Admittance Control</h1>
    
    </subsection>
  
  </section>

  <section><h1>Impedance control on the iiwa</h1>

    <p>As we discussed in the hardware chapter, the iiwa provides provides torque sensing and control via compliant elements at the joints.  The iiwa low-level controller (provided with the robot) actually provides an impedance control interface</p>

    <subsection><h1>Dynamics of elastic-joint robots</h1>
    
    </subsection>

    <subsection><h1>Joint impedance control</h1>
  
    </subsection>

    <subsection><h1>End-effector impedance control</h1>
    </subsection>

  </section>

  <section><h1>Putting it all together</h1>
  
  
  </section>

</chapter>
<!-- EVERYTHING BELOW THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter" href=segmentation.html>Previous Chapter</a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=drake.html>Next Chapter</a></td>
</tr></table>

<div id="footer">
  <hr>
  <table style="width:100%;">
    <tr><td><a href="https://accessibility.mit.edu/">Accessibility</a></td><td style="text-align:right">&copy; Russ
      Tedrake, 2020</td></tr>
  </table>
</div>


</body>
</html>
