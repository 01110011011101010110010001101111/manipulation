{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5-final"
    },
    "colab": {
      "name": "Robotic Manipulation - Geometric Pose Estimation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EgiF12Hf1Dhs",
        "colab_type": "text"
      },
      "source": [
        "**I recommend you run the first code cell of this notebook immediately, to start provisioning drake on the cloud machine, then you can leave this window open as you [read the textbook](manipulation.csail.mit.edu/pose.html).**\n",
        "\n",
        "# Notebook setup\n",
        "\n",
        "The following cell will:\n",
        "- on Colab (only), install Drake to `/opt/drake`, install Drake's prerequisites via `apt`, and add pydrake to `sys.path`.  This will take approximately two minutes on the first time it runs (to provision the machine), but should only need to reinstall once every 12 hours.  If you navigate between notebooks using Colab's \"File->Open\" menu, then you can avoid provisioning a separate machine for each notebook.\n",
        "- launch a server for our 3D visualizer (MeshCat) that will be used for the remainder of this notebook.\n",
        "\n",
        "You will need to rerun this cell if you restart the kernel, but it should be fast because the machine will already have drake installed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeMrMI0-1Dhu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import importlib\n",
        "import sys\n",
        "from urllib.request import urlretrieve\n",
        "\n",
        "if 'google.colab' in sys.modules and importlib.util.find_spec('manipulation') is None:\n",
        "    urlretrieve(f\"http://manipulation.csail.mit.edu/scripts/setup/setup_manipulation_colab.py\",\n",
        "                \"setup_manipulation_colab.py\")\n",
        "    from setup_manipulation_colab import setup_manipulation\n",
        "    setup_manipulation(manipulation_sha='master', drake_version='20200915', drake_build='nightly')\n",
        "\n",
        "# Determine if this notebook is currently running as a notebook or a unit test.\n",
        "from IPython import get_ipython\n",
        "running_as_notebook = get_ipython() and hasattr(get_ipython(), 'kernel')\n",
        "\n",
        "# Setup rendering (with xvfb), if necessary:\n",
        "import os\n",
        "if 'google.colab' in sys.modules and os.getenv(\"DISPLAY\") is None:\n",
        "    from pyvirtualdisplay import Display\n",
        "    display = Display(visible=0, size=(1400, 900))\n",
        "    display.start()\n",
        "\n",
        "# Start a single meshcat server instance to use for the remainder of this notebook.\n",
        "from meshcat.servers.zmqserver import start_zmq_server_as_subprocess\n",
        "server_args = []\n",
        "if 'google.colab' in sys.modules:\n",
        "    server_args = ['--ngrok_http_tunnel']\n",
        "proc, zmq_url, web_url = start_zmq_server_as_subprocess(server_args=server_args)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3o09CVeMUar",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's do all of our imports here, too.\n",
        "import numpy as np\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt, mpld3\n",
        "import pydot\n",
        "from IPython.display import display, SVG, HTML\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from pydrake.all import (\n",
        "    AddMultibodyPlantSceneGraph, BaseField, Box, ConnectMeshcatVisualizer, DepthCameraProperties, \n",
        "    DepthImageToPointCloud, DiagramBuilder, FindResourceOrThrow, FixedOffsetFrame, \n",
        "    GeometryInstance, MakeRenderEngineVtk, MakePhongIllustrationProperties, \n",
        "    MeshcatPointCloudVisualizer, Parser, RandomGenerator, RenderEngineVtkParams, RgbdSensor, RigidTransform, \n",
        "    RollPitchYaw, RotationMatrix, SpatialInertia, set_log_level, UniformlyRandomRotationMatrix, world_model_instance)\n",
        "from pydrake.examples.manipulation_station import ManipulationStation\n",
        "\n",
        "if running_as_notebook:\n",
        "    mpld3.enable_notebook()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7q0A14bAilIX",
        "colab_type": "text"
      },
      "source": [
        "# Simulating an RGB-D camera\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ILYLouFTjv6e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def DepthCameraDemoSystem():\n",
        "    builder = DiagramBuilder()\n",
        "\n",
        "    # Create the physics engine + scene graph.\n",
        "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0)\n",
        "    # Add a single object into it.\n",
        "    X_Mustard = RigidTransform(RollPitchYaw(-np.pi/2., 0, -np.pi/2.), [0, 0, 0.09515])\n",
        "    mustard = Parser(plant).AddModelFromFile(FindResourceOrThrow(\n",
        "        \"drake/manipulation/models/ycb/sdf/006_mustard_bottle.sdf\"))\n",
        "    plant.WeldFrames(plant.world_frame(), \n",
        "                     plant.GetFrameByName(\"base_link_mustard\", mustard), \n",
        "                     X_Mustard)\n",
        "    # Add a rendering engine\n",
        "    renderer = \"my_renderer\"\n",
        "    scene_graph.AddRenderer(renderer,\n",
        "                            MakeRenderEngineVtk(RenderEngineVtkParams()))\n",
        "\n",
        "    # TODO(russt): Use model directives for this\n",
        "    # Add a box for the camera in the environment.\n",
        "    X_Camera = RigidTransform(\n",
        "        RollPitchYaw(0, -0.2, 0.2).ToRotationMatrix().multiply(\n",
        "            RollPitchYaw(-np.pi/2.0, 0, np.pi/2.0).ToRotationMatrix()),\n",
        "        [.5, .1, .2])\n",
        "    camera_instance = plant.AddModelInstance(\"cameras\")\n",
        "    camera = plant.AddRigidBody(\"camera\", camera_instance, SpatialInertia())\n",
        "    plant.RegisterVisualGeometry(\n",
        "        camera, RigidTransform([0, 0, -0.01]), Box(width=.1, depth=.02, height=.02), \"D415\", \n",
        "        [.4, .4, .4, 1.])\n",
        "    plant.WeldFrames(plant.world_frame(), camera.body_frame(), X_Camera)\n",
        "\n",
        "    plant.Finalize()\n",
        "\n",
        "    frames_to_draw = {\"cameras\": \"camera\"}\n",
        "    meshcat = ConnectMeshcatVisualizer(builder, scene_graph, zmq_url=zmq_url, \n",
        "                                       delete_prefix_on_load=False,\n",
        "                                       frames_to_draw=frames_to_draw)\n",
        "    meshcat.load()\n",
        "\n",
        "    properties = DepthCameraProperties(width=640,\n",
        "                                       height=480,\n",
        "                                       fov_y=np.pi / 4.0,\n",
        "                                       renderer_name=renderer,\n",
        "                                       z_near=0.1,\n",
        "                                       z_far=10.0)\n",
        "    camera = builder.AddSystem(\n",
        "        RgbdSensor(parent_id=plant.GetBodyFrameIdOrThrow(camera.index()),\n",
        "                   X_PB=RigidTransform(),\n",
        "                   properties=properties,\n",
        "                   show_window=False))\n",
        "    camera.set_name(\"rgbd_sensor\")\n",
        "    builder.Connect(scene_graph.get_query_output_port(),\n",
        "                    camera.query_object_input_port())\n",
        "\n",
        "    # Export the camera outputs\n",
        "    builder.ExportOutput(camera.color_image_output_port(), \"color_image\")\n",
        "    builder.ExportOutput(camera.depth_image_32F_output_port(), \"depth_image\")\n",
        "\n",
        "    # Add a system to convert the camera output into a point cloud\n",
        "    to_point_cloud = builder.AddSystem(\n",
        "        DepthImageToPointCloud(camera_info=camera.depth_camera_info(),\n",
        "                               fields=BaseField.kXYZs | BaseField.kRGBs))\n",
        "    builder.Connect(camera.depth_image_32F_output_port(),\n",
        "                    to_point_cloud.depth_image_input_port())\n",
        "    builder.Connect(camera.color_image_output_port(),\n",
        "                    to_point_cloud.color_image_input_port())\n",
        "\n",
        "    # Send the point cloud to meshcat for visualization, too.\n",
        "    meshcat_pointcloud = builder.AddSystem(MeshcatPointCloudVisualizer(meshcat, X_WP=X_Camera))\n",
        "    builder.Connect(to_point_cloud.point_cloud_output_port(), meshcat_pointcloud.get_input_port())\n",
        "\n",
        "    # Export the point cloud output.\n",
        "    builder.ExportOutput(to_point_cloud.point_cloud_output_port(),\n",
        "                         \"point_cloud\")\n",
        "\n",
        "    diagram = builder.Build()\n",
        "    diagram.set_name(\"depth_camera_demo_system\")\n",
        "    return diagram\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "WCb1f0DmMUay",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_camera_images():\n",
        "    system = DepthCameraDemoSystem()\n",
        "\n",
        "    # Evaluate the camera output ports to get the images.\n",
        "    context = system.CreateDefaultContext()\n",
        "    system.Publish(context)\n",
        "    color_image = system.GetOutputPort(\"color_image\").Eval(context)\n",
        "    depth_image = system.GetOutputPort(\"depth_image\").Eval(context)\n",
        "\n",
        "    # Plot the two images.\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(color_image.data)\n",
        "    plt.title('Color image')\n",
        "    plt.subplot(122)\n",
        "    plt.imshow(np.squeeze(depth_image.data))\n",
        "    plt.title('Depth image')\n",
        "    #mpld3.display()\n",
        "    plt.show()\n",
        "\n",
        "plot_camera_images()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "Wya-_6_3MUa1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def draw_diagram():\n",
        "    system = DepthCameraDemoSystem()\n",
        "    display(SVG(pydot.graph_from_dot_data(system.GetGraphvizString(max_depth=1))[0].create_svg()))\n",
        "\n",
        "draw_diagram()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "mFNDRsZ1MUa4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_manipulation_station_camera_images():\n",
        "    station = ManipulationStation()\n",
        "    station.SetupManipulationClassStation()\n",
        "    # station.SetupClutterClearingStation()\n",
        "    station.Finalize()\n",
        "    context = station.CreateDefaultContext()\n",
        "\n",
        "    camera_names = station.get_camera_names()\n",
        "    index = 1\n",
        "    for name in camera_names:\n",
        "        color_image = station.GetOutputPort(\"camera_\" + name +\n",
        "                                            \"_rgb_image\").Eval(context)\n",
        "        depth_image = station.GetOutputPort(\"camera_\" + name +\n",
        "                                            \"_depth_image\").Eval(context)\n",
        "\n",
        "        plt.subplot(len(camera_names), 2, index)\n",
        "        plt.imshow(color_image.data)\n",
        "        index += 1\n",
        "        plt.title('Color image')\n",
        "        plt.subplot(len(camera_names), 2, index)\n",
        "        plt.imshow(np.squeeze(depth_image.data))\n",
        "        index += 1\n",
        "        plt.title('Depth image')\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "plot_manipulation_station_camera_images()    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9QDyRMCyb_gL",
        "colab_type": "text"
      },
      "source": [
        "# Point cloud registration with known correspondences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "vU_zEQJ_b1mv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def MakeModelAndScenePoints(Nm = 20):\n",
        "    \"\"\" Returns p_Om, p_s \"\"\"\n",
        "    random_state = np.random.RandomState()\n",
        "\n",
        "    # Make a random set of points to define our object in the x,y plane\n",
        "    l = 1.0 + 0.4*random_state.rand(1, Nm)\n",
        "    theta = np.arange(0, 2.0*np.pi, 2.0*np.pi/Nm)\n",
        "    p_Om = np.vstack((l * np.sin(theta), l * np.cos(theta), 0 * l))\n",
        "\n",
        "    # Make a random object pose, and apply it to get the scene points.\n",
        "    X_O = RigidTransform(RotationMatrix.MakeZRotation(np.pi*random_state.random()), 2.0*random_state.rand(3, 1))\n",
        "    p_s = X_O.multiply(p_Om)  # Consider adding noise here.\n",
        "    \n",
        "    return p_Om, p_s\n",
        "\n",
        "def PlotEstimate(p_Om, p_s, Xhat_O=RigidTransform(), chat=None, ax=None):\n",
        "    p_m = Xhat_O.multiply(p_Om)\n",
        "    if ax is None:\n",
        "        ax = plt.subplot()\n",
        "    artists = ax.plot(p_s[0, :], p_s[1, :], 'ro')\n",
        "    artists += ax.fill(p_s[0, :], p_s[1, :], 'lightsalmon')\n",
        "    artists += ax.plot(p_m[0, :], p_m[1, :], 'bo')\n",
        "    artists += ax.fill(p_m[0, :], p_m[1, :], 'lightblue', alpha=0.5)\n",
        "    if chat is not None:\n",
        "        artists += ax.plot(np.vstack((p_m[0, chat], p_s[0, :])), np.vstack((p_m[1, chat], p_s[1, :])), 'g--')\n",
        "    ax.axis('equal')\n",
        "    return artists\n",
        "\n",
        "def PoseEstimationGivenCorrespondences(p_Om, p_s, chat):\n",
        "    \"\"\" Returns optimal X_O given the correspondences \"\"\"\n",
        "    # Apply correspondences, and transpose data to support numpy broadcasting\n",
        "    p_Omc = p_Om[:, chat].T\n",
        "    p_s = p_s.T\n",
        "\n",
        "    # Calculate the central points\n",
        "    p_Ombar = p_Omc.mean(axis=0)\n",
        "    p_sbar = p_s.mean(axis=0)\n",
        "\n",
        "    # Calculate the \"error\" terms, and form the data matrix\n",
        "    merr = p_Omc - p_Ombar\n",
        "    serr = p_s - p_sbar\n",
        "    W = np.matmul(serr.T, merr)\n",
        "\n",
        "    # Compute R\n",
        "    U, Sigma, Vt = np.linalg.svd(W)\n",
        "    R = np.matmul(U, Vt)\n",
        "    if np.linalg.det(R) < 0:\n",
        "       print(\"fixing improper rotation\")\n",
        "       Vt[m - 1, :] *= -1\n",
        "       R = np.matmul(U, Vt)\n",
        "\n",
        "    # Compute p\n",
        "    p = p_sbar - np.matmul(R, p_Ombar)\n",
        "\n",
        "    return RigidTransform(RotationMatrix(R), p)\n",
        "\n",
        "\n",
        "Nm = 20\n",
        "p_Om, p_s = MakeModelAndScenePoints(Nm=20)\n",
        "Xhat = RigidTransform()\n",
        "c = np.arange(0,Nm)  # perfect, known correspondences\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "PlotEstimate(p_Om, p_s, Xhat, c, ax=ax[0])\n",
        "Xhat = PoseEstimationGivenCorrespondences(p_Om, p_s, c)\n",
        "ax[1].set_xlim(ax[0].get_xlim())\n",
        "ax[1].set_ylim(ax[0].get_ylim());\n",
        "PlotEstimate(p_Om, p_s, Xhat, c, ax=ax[1])\n",
        "ax[0].set_title('Original Data')\n",
        "ax[1].set_title('After Registration');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHfxMwrvb1mz",
        "colab_type": "text"
      },
      "source": [
        "# Iterative Closest Point (ICP)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "tags": [],
        "id": "N2cYjTpub1m0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FindClosestPoints(point_cloud_A, point_cloud_B):\n",
        "    \"\"\"\n",
        "    Finds the nearest (Euclidean) neighbor in point_cloud_B for each\n",
        "    point in point_cloud_A.\n",
        "    @param point_cloud_A A 3xN numpy array of points.\n",
        "    @param point_cloud_B A 3xN numpy array of points.\n",
        "    @return indices An (N, ) numpy array of the indices in point_cloud_B of each\n",
        "        point_cloud_A point's nearest neighbor.\n",
        "    @return distances An (N, ) numpy array of Euclidean distances from each\n",
        "        point in point_cloud_A to its nearest neighbor in point_cloud_B.\n",
        "    \"\"\"\n",
        "    distances = np.zeros(point_cloud_A.shape[1])\n",
        "    indices = np.zeros(point_cloud_A.shape[1])\n",
        "\n",
        "    neigh = NearestNeighbors(n_neighbors=1)\n",
        "    neigh.fit(point_cloud_B.T)\n",
        "    distances, indices = neigh.kneighbors(point_cloud_A.T, return_distance=True)\n",
        "\n",
        "    distances = distances.ravel()\n",
        "    indices = indices.ravel()\n",
        "\n",
        "    return indices, distances\n",
        "\n",
        "Nm = 20\n",
        "p_Om, p_s = MakeModelAndScenePoints(Nm=20)\n",
        "Xhat = RigidTransform()\n",
        "chat_previous = np.zeros(Nm)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "frames = []\n",
        "frames.append(PlotEstimate(p_Om=p_Om, p_s=p_s, Xhat_O=Xhat, chat=None, ax=ax))\n",
        "\n",
        "while True:\n",
        "    chat, distances = FindClosestPoints(p_s, Xhat.multiply(p_Om))\n",
        "    if np.array_equal(chat, chat_previous):\n",
        "        # Then I've converged.\n",
        "        break\n",
        "    chat_previous = chat\n",
        "    frames.append(PlotEstimate(p_Om=p_Om, p_s=p_s, Xhat_O=Xhat, chat=chat, ax=ax))\n",
        "    Xhat = PoseEstimationGivenCorrespondences(p_Om, p_s, chat)\n",
        "    frames.append(PlotEstimate(p_Om=p_Om, p_s=p_s, Xhat_O=Xhat, chat=None, ax=ax))\n",
        "\n",
        "ani = animation.ArtistAnimation(fig, frames, interval=400)\n",
        "\n",
        "display(HTML(ani.to_jshtml()))\n",
        "plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WLMLxAJJb1m2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}