{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgiF12Hf1Dhs"
   },
   "source": [
    "This notebook provides examples to go along with the [textbook](http://manipulation.csail.mit.edu/rl.html).  I recommend having both windows open, side-by-side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from pydrake.all import (\n",
    "    InputPort, EventStatus, OutputPort, PortDataType, RandomGenerator, \n",
    "    Simulator,\n",
    ")\n",
    "\n",
    "class DrakeGymEnv(gym.Env):\n",
    "\n",
    "    def __init__(self,\n",
    "                 system,\n",
    "                 time_step,\n",
    "                 reward_callback_or_port,\n",
    "                 action_port=None,\n",
    "                 action_space=None,\n",
    "                 observation_port=None,\n",
    "                 observation_space=None,\n",
    "                 render_rgb_port=None):\n",
    "        self.system = system\n",
    "        self.time_step = time_step\n",
    "        self.simulator = Simulator(self.system)\n",
    "        self.generator = RandomGenerator()\n",
    "\n",
    "        # Setup rewards\n",
    "        if isinstance(reward_callback_or_port, OutputPort):\n",
    "            self.reward = lambda context: reward_callback_or_port(context)\n",
    "        else:\n",
    "            assert callable(reward_callback_or_port)\n",
    "            self.reward = reward_callback_or_port\n",
    "\n",
    "        # Setup actions (resorting to defaults whenever possible)\n",
    "        if action_port:\n",
    "            assert isinstance(action_port, InputPort)\n",
    "            self.action_port = action_port\n",
    "        else:\n",
    "            assert system.num_input_ports() == 1\n",
    "            self.action_port = system.get_input_port()\n",
    "        if action_space:\n",
    "            self.action_space = action_space\n",
    "            if self.action_port.get_data_type() == PortDataType.kVectorValued:\n",
    "                assert np.array_equal(self.action_space.shape, [\n",
    "                                      self.action_port.size()])\n",
    "        elif self.action_port.get_data_type() == PortDataType.kVectorValued:\n",
    "            # TODO(russt): Is this helpful, or is it better to force people to \n",
    "            # specify a bounded box?\n",
    "            num_actions = self.action_port.size()\n",
    "            self.action_space = gym.spaces.Box(\n",
    "                low=np.full((num_actions), -np.inf),\n",
    "                high=np.full((num_actions), np.inf))\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Could not infer the action space from your action port; please pass in the action_space argument.\")\n",
    "\n",
    "        # Setup observations (resorting to defaults whenever possible)\n",
    "        if observation_port:\n",
    "            assert isinstance(observation_port, OutputPort)\n",
    "            self.observation_port = observation_port\n",
    "        else:\n",
    "            if isinstance(reward_callback_or_port, OutputPort):\n",
    "                assert system.num_output_ports() == 2\n",
    "                possible_port_indices = [0, 1]\n",
    "                possible_port_indices.remove(\n",
    "                    reward_callback_or_port.get_index())\n",
    "                self.observation_port = system.get_output_port(\n",
    "                    possible_port_indices[0])\n",
    "            else:\n",
    "                assert system.num_output_ports() == 1\n",
    "                self.observation_port = system.get_output_port()\n",
    "        if observation_space:\n",
    "            self.observation_space = observation_space\n",
    "            if self.observation_port.get_data_type() == \\\n",
    "                PortDataType.kVectorValued:\n",
    "                assert np.array_equal(self.observation_space.shape, [\n",
    "                                      self.observation_port.size()])\n",
    "        elif self.observation_port.get_data_type() == \\\n",
    "                PortDataType.kVectorValued:\n",
    "            # TODO(russt): Is this helpful, or is it better to force people to \n",
    "            # specify a bounded box?\n",
    "            num_obs = self.observation_port.size()\n",
    "            self.observation_space = gym.spaces.Box(\n",
    "                low=np.full((num_obs), -np.inf),\n",
    "                high=np.full((num_obs), np.inf))\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                \"Could not infer the observation space from your observation port; please pass in the observation_space argument.\")\n",
    "\n",
    "        self.metadata['render.modes'] = ['human', 'ascii']\n",
    "\n",
    "        # (Maybe) setup rendering\n",
    "        if render_rgb_port:\n",
    "            assert isinstance(render_rgb_port, OutputPort)\n",
    "            assert render_rgb_port.get_data_type() == \\\n",
    "                PortDataType.kAbstractValued\n",
    "            self.metadata['render.modes'].append('rgb_array')\n",
    "        self.render_rgb_port = render_rgb_port\n",
    "\n",
    "    def step(self, action):\n",
    "        context = self.simulator.get_context()\n",
    "        time = context.get_time()\n",
    "\n",
    "        self.action_port.FixValue(context, action)\n",
    "        self.simulator.AdvanceTo(time + self.time_step)\n",
    "\n",
    "        observation = self.observation_port.Eval(context)\n",
    "        reward = self.reward(context)\n",
    "        done = False\n",
    "        monitor = self.simulator.get_monitor()\n",
    "        if monitor:\n",
    "            status = monitor(context)\n",
    "            done = status == EventStatus.kReachedTermination or \\\n",
    "                status == EventStatus.kFailed\n",
    "        info = dict()\n",
    "\n",
    "        return observation, reward, done, info\n",
    "\n",
    "    def reset(self):\n",
    "        context = self.simulator.get_mutable_context()\n",
    "        self.system.SetRandomContext(context, self.generator)\n",
    "        self.simulator.Initialize()\n",
    "        # Note: The output port will be evaluated without fixing the input port.\n",
    "        return self.observation_port.Eval(context)\n",
    "    \n",
    "    def render(self, mode='human'):\n",
    "        if mode == 'human':\n",
    "            self.system.Publish(self.simulator.get_context())\n",
    "            return\n",
    "        elif mode == 'ansi':\n",
    "            return str(self.simulator.get_context())\n",
    "        elif mode == 'rgb_array':\n",
    "            assert self.render_rgb_port, \\\n",
    "                \"You must set render_rgb_port in the constructor\"\n",
    "            return np.array(self.rgb_port.Eval(context))\n",
    "        else:\n",
    "            super(DrakeGym, self).render(mode=mode)\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        if seed:\n",
    "            self.generator = RandomGenerator(seed)\n",
    "        else:\n",
    "            seed = self.generator()\n",
    "        # Note: One could call self.action_space.seed(self.generator()) here, \n",
    "        # but it appears that is not the standard approach:\n",
    "        # https://github.com/openai/gym/issues/681\n",
    "        return [seed]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from manipulation.meshcat_cpp_utils import StartMeshcat\n",
    "\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydrake.all import (\n",
    "    DiagramBuilder, SceneGraph, MeshcatVisualizerCpp, MeshcatVisualizerParams\n",
    ")\n",
    "from pydrake.examples.pendulum import PendulumPlant, PendulumGeometry\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "def PendulumExample():\n",
    "    builder = DiagramBuilder()\n",
    "    plant = builder.AddSystem(PendulumPlant())\n",
    "    scene_graph = builder.AddSystem(SceneGraph())\n",
    "    PendulumGeometry.AddToBuilder(\n",
    "        builder, plant.get_state_output_port(), scene_graph)\n",
    "    MeshcatVisualizerCpp.AddToBuilder(\n",
    "        builder, scene_graph, meshcat, \n",
    "        MeshcatVisualizerParams(publish_period=np.inf))\n",
    "    \n",
    "    builder.ExportInput(plant.get_input_port(), \"torque\")\n",
    "    builder.ExportOutput(plant.get_state_output_port(), \"state\")\n",
    "    diagram = builder.Build()\n",
    "\n",
    "    def reward(context):\n",
    "        plant_context = plant.GetMyContextFromRoot(context)\n",
    "        state = plant_context.get_continuous_state_vector()\n",
    "        u = plant.get_input_port().Eval(plant_context)[0]\n",
    "        theta = state[0] % 2*np.pi  # Wrap to 2*pi\n",
    "        theta_dot = state[1]\n",
    "        return (theta-np.pi)**2 + 0.1*theta_dot**2 + 0.001*u\n",
    "\n",
    "    env = DrakeGymEnv(diagram, time_step=0.05, reward_callback_or_port=reward)\n",
    "    check_env(env)\n",
    "\n",
    "    max_torque = 3\n",
    "    env = DrakeGymEnv(diagram, time_step=0.05, reward_callback_or_port=reward, \n",
    "                      action_space=gym.spaces.Box(low=np.array([-max_torque]),\n",
    "                                                  high=np.array([max_torque])))\n",
    "\n",
    "PendulumExample()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DrakeMultibodyGym(DrakeGym):\n",
    "    def __init__(robot_description_file,\n",
    "                 time_step,\n",
    "                 multibody_time_step=0.0, viewer='meshcat', X_WCamera=None):\n",
    "        builder = DiagramBuilder()\n",
    "        self.plant, self.scene_graph = AddMultibodyPlantSceneGraph(\n",
    "            builder, time_step=multibody_time_step)\n",
    "        parser = Parser(self.plant)\n",
    "        parser.AddRobotFromFile(robot_description_file)\n",
    "        self.plant.Finalize()\n",
    "\n",
    "        # TODO(russt): Add a viewer\n",
    "        # TODO(russt): Add a camera\n",
    "        builder.ExportInput(self.plant.get_actuation_input_port(), \n",
    "                            \"actuation\")\n",
    "        builder.ExportOutput(self.plant.get_state_output_port(),\n",
    "                                \"state\")\n",
    "\n",
    "        super().__init__(builder.Build(), time_step)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Robotic Manipulation - Geometric Pose Estimation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
