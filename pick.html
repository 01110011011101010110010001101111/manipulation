<!DOCTYPE html>

<html>

  <head>
    <title>Robotic Manipulation: Basic Pick and Place</title>
    <meta name="Robotic Manipulation: Basic Pick and Place" content="text/html; charset=utf-8;" />
    <link rel="canonical" href="http://manipulation.csail.mit.edu/pick.html" />

    <script src="https://hypothes.is/embed.js" async></script>
    <script type="text/javascript" src="htmlbook/book.js"></script>

    <script src="htmlbook/mathjax-config.js" defer></script> 
    <script type="text/javascript" id="MathJax-script" defer
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js">
    </script>
    <script>window.MathJax || document.write('<script type="text/javascript" src="htmlbook/MathJax/es5/tex-chtml.js" defer><\/script>')</script>

    <link rel="stylesheet" href="htmlbook/highlight/styles/default.css">
    <script src="htmlbook/highlight/highlight.pack.js"></script> <!-- http://highlightjs.readthedocs.io/en/latest/css-classes-reference.html#language-names-and-aliases -->
    <script>hljs.initHighlightingOnLoad();</script>

    <link rel="stylesheet" type="text/css" href="htmlbook/book.css" />
  </head>

<body onload="loadChapter('manipulation');">

<div data-type="titlepage">
  <header>
    <h1><a href="index.html" style="text-decoration:none;">Robotic Manipulation</a></h1>
    <p data-type="subtitle">Perception, Planning, and Control</p> 
    <p style="font-size: 18px;"><a href="http://people.csail.mit.edu/russt/">Russ Tedrake</a></p>
    <p style="font-size: 14px; text-align: right;"> 
      &copy; Russ Tedrake, 2020<br/>
      <a href="misc.html">How to cite these notes, use annotations, and give feedback.</a><br/>
    </p>
  </header>
</div>

<p><b>Note:</b> These are working notes used for <a
href="http://manipulation.csail.mit.edu/Fall2020/">a course being taught
at MIT</a>. They will be updated throughout the Fall 2020 semester.  <!-- <a 
href="https://www.youtube.com/channel/UChfUOAhz7ynELF-s_1LPpWg">Lecture  videos are available on YouTube</a>.--></p> 

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter" href=robot.html>Previous Chapter</a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=pixels.html>Next Chapter</a></td>
</tr></table>


<!-- EVERYTHING ABOVE THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->
<chapter style="counter-reset: chapter 2"><h1>Basic Pick and Place</h1>
  <a style="float:right; margin-top:-80px;" target="pick" href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pick.ipynb"><img src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open Corresponding Notebook In Colab"/></a>
  <div style="clear:right;"></div>

  <figure>
    <img src="figures/pick.png" style="width:70%"/>
    <figcaption>Your challenge: command the robot to pick up the brick and place
    it in a desired position/orientation.</figcaption>
    <todo>Update this image once we get a better schunk model.</todo>
  </figure>

  <p>The stage is set.  You have your robot.  I have a little red brick.  I'm
  going to put it on the table in front of your robot, and your goal is to move
  it to a desired position/orientation on the table.  I want to defer the
  <i>perception</i> problem for one chapter, and will let you assume that you
  have access to a perfect measurement of the current position/orientation of
  the brick.  Even without perception, completing this task this requires us to
  build up a basic toolkit for geometry and kinematics; it's a natural place to
  start.</p>

  <p>First, we will establish some terminology and notation for kinematics. This
  is one area where careful notation can yield dividends, and sloppy notation
  will inevitably lead to confusion and bugs.  The Drake developers have gone to
  great length to establish and document a consistent <a
  href="https://drake.mit.edu/doxygen_cxx/group__multibody__notation.html">
  multibody notation</a>, which they call "Monogram Notation".  The
  documentation even includes some of the motivation/philosophy behind that
  notation. I'll use the monogram notation throughout this text.</p>
  
  <p>If you'd like a more extensive background on kinematics than what I provide
  here, my favorite reference is still <elib>Craig05</elib>.  For free online
  resources, Chapters 2 and 3 of the 1994 book by Murray et al. (now free
  online)<elib>Murray94</elib> are also excellent, as are the first seven
  chapters of <a
  href="http://hades.mech.northwestern.edu/index.php/Modern_Robotics">Modern
  Robotics</a> by Lynch and Park<elib>Lynch17</elib> (they also have excellent
  accompanying videos).  Unfortunately, with three different references you'll
  get three (slightly) different notations; mine is most similar to
  <elib>Craig05</elib>.</p>
    
  <p>Please don't get overwhelmed by how much background material there is to
  know!  I am personally of the opinion that a clear understanding of just a few
  basic ideas should make you very effective here.  The details will come
  later, if you need them.</p>    

  <section><h1>Kinematics Notation</h1>

    <p><i>The following concepts are disarmingly subtle. I've seen incredibly
    smart people assume they knew them and then perpetually stumble over
    notation.  I did it for years myself.  Take a minute to read this
    carefully!</i></p>

    <p>Perhaps the most fundamental concept in geometry is the concept of a
    point.  Points occupy a position in space, and they can have names, e.g.
    point $A$, $C$, or more descriptive names like $B_{com}$ for the center of
    mass of body $B$. We'll denote the position of the point as $p^A$; that's
    $p$ for position, and not for point, because other geometric quantities can
    also have a position.</p>

    <p>But let's be more careful.  Position is actually a relative quantity.
    Really, we should only ever write the position of two points relative to
    each other. We'll use e.g. $^Ap^C$ to denote the position of $C$ relative to
    $A$.  The left superscript looks mighty strange, but we'll see that it pays
    off once we start transforming points.</p>
    
    <p>Every time we describe the (relative) position as a vector of numbers, we
    need to be explicit about the coordinate system.  All of our coordinate
    systems here will follow the "right-hand rule". We'll give a coordinate
    system, coordinate frame, or just <i>frame</i>, a name, too, like $F$.  If I
    want to write the position of point $C$ relative to point $A$, expressed in
    frame $F$, I will write $[^Ap^C]_F$.  The brackets come in because we'll
    sometimes what to refer to the elements of the position, e.g. $[^Ap_i^C]_F$
    is the $i$th element.</p>
    
    <p>That is seriously heavy notation.  I don't love it myself, but it's
    the most durable I've got, and we'll have shorthand for when the context is
    clear.</p>

    <p><img style="height:90px;float:left;margin-right:10px"
    src="figures/coordinate_frames.png"/> There are a few very special frames.
    We use $W$ to denote the <i>world frame</i>.  We think about the world frame
    in Drake using vehicle coordinates (positive $x$ to the front, positive $y$
    to the <i>left</i>, and positive $z$ is up).  The other particularly special
    frames are the <i>body frames</i>: every body in the multibody system has a
    unique frame attached to it.  We'll typically use $B_i$ to denote the frame
    for body $i$.</p>

    <p>Frames have a position, too -- it coincides with the frame origin.  So it
    is perfectly valid to write $[^Wp^A]_W$ to denote the position of point $A$
    relative to the origin of the world frame, expressed in the world frame.
    Here is where the shorthand comes in.  If the position of a quantity is
    relative to a frame, and expressed in the same frame, then we can safely
    omit the brackets and the subscript.  $^Fp^A \equiv [^Fp^A]_F$. Furthermore,
    if the "relative to" field is omitted, then we assume that the point is
    relative to $W$, so $p^A \equiv [^Wp^A]_W$.</p>

    <figure>
      <img style="width:60%" src="figures/notation.svg"></img>
      <!-- Note: I made this in slides.com, exported to pdf, cropped in acrobat,
      then converted with pdf2svg. -->
    </figure>

    <p>Frames also have an orientation.  We'll use $R$ to denote a
    <i>rotation</i>, and follow the same notation, writing $^BR^A$ to denote the
    rotation of frame $A$ relative to frame $B$.  Unlike vectors, pure rotations
    do not have an additional "expressed in" frame.</p>

    <p>A frame $F$ can be specified completely by a position and rotation
    relative to another frame.  Taken together, we call the position and
    rotation a <a
    href="https://drake.mit.edu/doxygen_cxx/group__multibody__spatial__pose.html">
    <i>spatial pose</i></a>, or just <i>pose</i>.  A <i>spatial transform</i>,
    or just <i>transform</i>, is the "verb form" of pose.  In Drake we use <a
    href="https://drake.mit.edu/doxygen_cxx/classdrake_1_1math_1_1_rigid_transform.html"><code>RigidTransform</code></a>
    to represent a pose/transform, and denote it with the letter $X$. $^BX^A$ is
    the pose of frame $A$ relative to frame $B$.  When we talk about the pose of
    an object $O$, without mentioning a reference frame explicitly, we mean
    $^WX^O$ where $O$ is the body frame of the object.</p>
    
    <p>The Drake <a
    href="https://drake.mit.edu/doxygen_cxx/group__multibody__notation.html">
    documentation</a> also discusses how to use this notation in code. In short,
    $[^Bp_i^A]_C$ is written <code>pi_BA_C</code>. It works, I promise.</p>

    <!--
    <subsection><h1>Rotation representations</h1>
    
      <p>There is some subtly on how we choose to represent a relative pose /
      rigid transform, due the various ways that we can represent a rotation.</p>

      <p>Quaternions, Euler angles, Axis angles, Rotation matrices.</p>
      <p>We'll get into them if/when we need to, but for now it's sufficient to
      understand that `RigidTransform`...</p>

      <p>Everything is better in 2D.  We can use a scalar rotation angle to
      completely specify a rotation represented in a frame, and we can convert
      seamlessly between this scalar and the 2D rotation matrices.  I'll try to
      use 2D examples to demonstrate core concepts whenever possible.</p>

    </subsection>
    <example><h1>Pose in 2D</h1>
      <todo>Colab example with sliders for x,z,theta.  Mustard bottle?</todo>
    
    </example>

    <example><h1>Pose in 3D</h1>
      <todo>Colab example with pose sliders.  Mustard bottle?  But also output, at least in text, the other representations.</todo>
    </example>
-->

  </section>

  <section><h1>Pick and place via spatial transforms</h1>
  
    <p>Now that we have the notation, we can formulate our approach to the basic
    pick and place problem.  Let us call our object, $O$, and our gripper, $G$.
    Our idealized perception sensor tells us $^WX^O$.  Let's create a frame
    $O_d$ to denote the describe the "desired" pose of the object, $^WX^{O_d}$.
    So pick and place manipulation is simply trying to make $X^O = X^{O_d}$.</p>
    
    <todo>Add a figure here (after Terry's PR lands).</todo>

    <div>To accomplish this, we will assume that the object doesn't move
    relative to the world ($^WX^O$ is constant) when the gripper is open, and
    the object doesn't move relative to the gripper ($^GX^O$ is constant) when
    the gripper is closed.  Then we can:
      <ul style="margin:0"><li>move the gripper in the world, $X^G$, to an
      appropriate pose relative to the object: $^OX^G$.</li>
      <li>close the gripper.</li>
      <li>move the gripper+object to the desired pose, $X^O = X^{O_d}$.</li>
      <li>open the gripper, and retract the hand.</li>
      </ul>
    To simplify the problem of approaching the object (without colliding with
    it) and retracting from the object, we will insert a "pregrasp pose",
    $X^{G_{pre}}$, above the object as an intermediate step.
    </div>

    <p>Clearly, programming this strategy requires good tools for working with
    these transforms, and for relating the pose of the gripper to the joint
    angles of the robot.</p>
  </section>

  <section><h1>Spatial Algebra</h1>
  
    <p>Here is where we start to see the pay-off from our heavy notation, as we
    define the rules of converting positions, rotations, poses, etc. between
    different coordinate frames.  Without the notation, this invariably involves
    me with my right hand in the air making the "right-hand rule", and my head
    twisting around in space.  With the notation, it's a simple matter of lining
    up the symbols properly, and we're more likely to get the right answer!</p>
  
    <div>
    Here are the basic rules of algebra for our spatial quantities:  
    <ul>
      <li>Positions expressed in the same frame can be added when their
      reference and target symbols match: $$[^Ap^B]_F + [^Bp^C]_F = [^Ap^C]_F.$$
      The additive inverse is well defined: $$[^Ap^B]_F = - [^Bp^A]_F.$$ Those
      should be pretty intuitive; make sure you confirm them for yourself.</li>
      <li>Multiplication by a rotation can be used to change the "expressed in"
      frame: $$[^Ap^B]_G = {^GR^F} [^Ap^B]_F.$$  You might be surprised that a
      rotation alone is enough to change the expressed-in frame, but it's true.
      The position of the expressed-in frame does <i>not</i>
      effect the relative position between two points.</li>
      <li>Rotations can be multiplied when their reference and target symbols
      match: $${^AR^B} {^BR^C} = {^AR^C}.$$  The inverse operation is also
      simply defined: $$[^AR^B]^{-1} = {^BR^A}.$$  When the rotation is
      represented as a rotation matrix, this is literally the matrix inverse,
      and since rotation matrices are orthonormal, we also have
      $R^{-1}=R^T.$</li>
      <li>Transforms bundle this up into a single, convenient notation when
      positions are relative to a frame (and the same frame they are expressed
      in): $${^Gp^A} = {^GX^F} {^Fp^A} = {^Gp^F} + {^GR^F}{^Fp^A}.$$</li>
      <li>Transforms compose: $${^AX^B} {^BX^C} = {^AX^C},$$  and have an inverse $$[^AX^B]^{-1} = {^BX^A}.$$</li>
    </ul></div>

    <p>In practice, transforms are implemented using <a
    href="https://drake.mit.edu/doxygen_cxx/group__multibody__spatial__pose.html">homogenous
    coordinates</a>, but for now I'm happy to leave that as an implementation
    detail.</p>

    <example><h1>From camera coordinates to world coordinates</h1>
      
      <todo>Add a figure here.</todo>

      <p>Imagine that I have a depth camera mounted in a fixed pose in my
      workspace.  Let's call the camera frame $C$ and denote its pose in the
      world with $^WX^C$.  This pose is often called the camera
      "extrinsics".</p>

      <p>A depth camera returns points in the camera coordinates.  Therefore,
      we'll write this position of point $P_i$ with $^Cp^{P_i}$.  If we want to
      convert the point into the world coordinates, we simply have $$p^{P_i} =
      X^C {^Cp^{P_i}}.$$</p>

      <p>This is a work-horse operation for us.  We often aim to merge points
      from multiple cameras (typically in the world frame), and always need to
      somehow relate the frames of the camera with the frames of the robot.</p>
    
    </example>

  </section>

  <section><h1>Forward kinematics</h1>
  
    <p>The spatial algebra gets us pretty close to what we need for our pick and
    place algorithm.  But remember that the interface we have to the robot
    reports measured joint positions, and expects commands in the form of joint
    positions.  So our remaining task is to convert between joint angles and
    cartesian frames.  We'll do this in steps, the first step is to go from
    joint positions to cartesian frames: this is known as <i>forward
    kinematics</i>.

    <p>Throughout this text, we will refer to the joint positions of the robot
    (also known as "configuration" of the robot) using a vector $q$.  If the
    configuration of the scene includes objects in the environment as well as
    the robot, we would use $q$ for the entire configuration vector, and use
    e.g. $q_{robot}$ for the subset of the vector corresponding to the robot's
    joint positions. Therefore, the goal of forward kinematics is to produce a
    map: $$X^B = f_{kin}^B(q),$$ for any body $B$ (or any other frame we have
    attached to the scene).  Our spatial notation and spatial algebra makes this
    computation relatively straight-forward.</p>

    <subsection><h1>The kinematic tree</h1>

      <p>In order to facilitate kinematics and related multibody computations,
      the <code>MultibodyPlant</code> organizes all of the bodies in the world
      into a tree topology.  Every body (except the world body) has a parent,
      which it is connected to via either a <code>Joint</code> or a "floating
      base".</p>

      <example><h1>Inspecting the kinematic tree</h1>

        <p>Drake provides some visualization support for inspecting the
        kinematic tree data structure.  The kinematic tree for an iiwa is more
        of a vine than a tree (it's a serial manipulator), but the tree for the
        dexterous hands are more interesting.  I've added our brick to the
        example, too, so that you can see that a "free" body is just another
        branch off the world root node.</p>

        <p><a target="pick"
          href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pick.ipynb#scrollTo=ILYLouFTjv6e"><img
          src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
          </p>
    
        <todo>Insert topology visualization here (once it is better)</todo>
      </example>

      <p>Every <code>Joint</code> and "floating base" has some number of
      position variables associated with it -- a subset of the configuration
      vector $q$ -- and knows how to compute the configuration dependent
      transform across the joint from the outboard frame $M$ to the inboard
      frame $F$: $^{F}X^{M}(q)$.  Additionally, the kinematic tree defines the
      (fixed) transforms from the child body frame to the joint frame,
      $^{M}X^C$, and from the joint frame to the parent frame, $^PX^{F}$.
      Altogether, we can compute the configuration transform between any one
      body and its parent, $$^PX^C(q) = \left[^PX^F\right] \left[^FX^M(q)\right]
      \left[^MX^C\right].$$</p>

      <example><h1>Specifying the kinematic tree in URDF</h1></example>

      <example><h1>Specifying the kinematic tree in SDF</h1></example>

      <p>You might be tempted to think that every time you add a joint to the
      <code>MultibodyPlant</code>, you are adding a degree of freedom.  But it
      actually works the other way around.  Every time you add a <i>body</i>
      to the plant, you are adding many degrees of freedom.  But you can then
      add joints to <i>remove</i> those degrees of freedom; joints are
      constraints.  "Welding" the robot's base to the world frame removes all of
      the floating degrees of freedom of the base.  Adding a rotational joint
      between a child body and a parent body removes all but one degree of
      freedom, etc.</p>

      <p>Interestingly, <code>SceneGraph</code> (the geometry engine) does not
      maintain any tree structure.  All that <code>SceneGraph</code> knows about
      is a list of frames specified relative to the world frame, $W$, and a list
      of geometries attached to each frame.</p> 
    
    </subsection>

    <subsection><h1>Forward kinematics for pick and place</h1>
    
      <p>In order to compute the pose of the gripper in the world, $X^G$, we
      simply query the parent of the gripper frame in the kinematic tree, and
      recursively compose the transforms until we get to the world frame.</p>

      <figure>
        <img style="width:40%;margin-right:40px"
        src="figures/kinematic_frames_iiwa.png"/><img style="width:40%"
        src="figures/kinematic_frames_gripper.png"/>
        <figcaption>Kinematic frames on the iiwa (left) and the WSG (right).
        For each frame, the <span style="color:red">positive $x$ axis is in
        red</span>, the <span style="color:green">positive $y$ axis is in
        green</span>, and the <span style="color:blue">positive $z$ axis is in
        blue</span>.</figcaption>
      </figure>

      <example><h1>Forward kinematics for the gripper frame</h1>
      
        <p>Let's evaluate the pose of the gripper in the world frame: $X^G$.  We
        know that it will be a function of configuration of the robot, which is
        just a part of the total state of the <code>MultibodyPlant</code>.  The
        following example shows you how it works.</p>

        <p><a target="pick"
          href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pick.ipynb#scrollTo=5SjOClhTltPk"><img
          src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
          </p>

        <p>The key lines are 
          <code class="language-python"><pre>
gripper = plant.GetBodyByName("body")
pose = plant.EvalBodyPoseInWorld(context, gripper)</pre></code>
        Behind the scenes, the <code>MultibodyPlant</code> is doing all of the
        spatial algebra we described above to return the pose (and also some
        clever caching because you can reuse much of the computation when if you
        want to evaluate the pose of another frame on the same robot).  
        </p>

      </example>

      <example><h1>Forward kinematics of "floating-base" objects</h1>
      
        <p>Consider the special case of having a <code>MultibodyPlant</code>
        with exactly one body added, and no joints.  The kinematic tree is
        simply the world frame, the body frame, and they are connected by the
        "floating base".  What does the forward kinematics function: $$X^B =
        f_{kin}^B(q),$$ look like in that case?  If $q$ is already representing
        the floating-base configuration, is $f^B_{kin}$ just the identity
        function?</p>

        <p>This gets into the subtle points of how we represent transforms, and
        how we represent rotations in particular.  There are many possible
        representations of 3D rotations, they are good for different things, and
        unfortunately, there is no one representation to rule them all. (This is
        one of the many reasons why everything is better in 2D!)  Common
        representations include 3x3 rotation matrices, Euler angles (e.g.
        Roll-Pitch-Yaw), axis angle, and unit quaternions. In Drake, we provide
        all of these representations, and make it easy to convert back and forth
        between them.  In order to make the spatial algebra efficient, we use
        rotation matrices in our <code>RigidTransform</code>, but in order to
        have a more compact representation of configuration we use unit
        quaternions in our configuration vector, $q$.</p>

        <p>As a result, for this example, the software implementation of the
        function $f_{kin}^B$ is precisely the function that converts the
        position $\times$ unit quaternion representation into the position
        $\times$ rotation matrix representation.</p>
      </example>

    </subsection>

  </section>

  <section><h1>Differential kinematics (Jacobians)</h1>

    <p>The forward kinematics machinery gives us the ability to compute the pose
    of the gripper and the pose of the object, both in world coordinates.  But
    if our goal is to <i>move</i> the gripper to the object, then we should
    understand how changes in the joint angles relate to changes in the gripper
    pose.  This is traditionally referred to as "differential kinematics".</p>

    <p>At first blush, this is straightforward.  The change in pose is related
    to a change in joint positions by the (partial) derivative of the forward
    kinematics:  \begin{equation}dX^B = \pd{f_{kin}^B(q)}{q} dq = J^B(q)dq.
    \label{eq:jacobian}\end{equation} Partial derivatives of a function are
    referred to as "Jacobians" in many fields; in robotics it's rare to refer to
    derivatives of the kinematics as anything else.</p>

    <p>All of the subtlety, again, comes in because of the multiple
    representations that we have for 3D rotations (rotation matrix, unit
    quaternions, ...).  While there is no one best representation for 3D
    rotations, it <i>is</i> possible to have one canonical representation for
    differential rotations.  Without any loss of generality, we can represent
    the rate of change in rotation using a six-element vector for <a
    href="https://drake.mit.edu/doxygen_cxx/group__multibody__spatial__vectors.html"><i>spatial
    velocity</i></a>: $$^BV^C = \begin{bmatrix} ^B\omega^C \\ ^B\text{v}^C
    \end{bmatrix}.$$ $^BV^C$ is the spatial velocity of frame $C$ in frame $B$,
    $^B\omega^C \in \Re^3$ is the <i>angular velocity</i> (of frame $C$ in frame
    $B$), and $^B\text{v}^C \in \Re^3$ is the <i>translational velocity</i>.  So
    there are actually <b>many</b> different kinematic Jacobians, depending on
    which representation of 3D orientation you are using on the right-hand side
    and on the left-hand side of equation \eqref{eq:jacobian}.</p>

    <p>There is one more velocity to be aware of: I'll use $v$ to denote the
    generalized velocity vector of the plant.  While a spatial velocity $^BV^C$
    is six elements, a translational velocity $^B\text{v}^C$ is three elements,
    the generalized velocity vector is whatever size it needs to be to encode
    the time derivatives of the configuration variables, $q$.  For the iiwa
    welded to the world frame, that means it has seven elements.  I've tried to
    be careful to typeset each of these v's differently throughout the notes.
    Almost always the distinction is also clear from the context.</p>

    <example><h1>Don't assume $\dot{q} \equiv v$</h1>
    
      <p><i>TODO: One free body.  The state vector is 13 elements.  Huh?</i></p>
    
    </example>

    <p>You may hear the terms "analytic Jacobian", which refers to the explicit
    partial derivative of the forward kinematics, and "geometric Jacobian" which
    replaces 3D rotations on the left-hand side with spatial velocities.  In
    Drake's <code>MultibodyPlant</code>, we have decided to err on the side of
    clarity, and offer 
    <ul>
      <li> <code>CalcJacobianAngularVelocity</code>,</li>
      <li><code>CalcJacobianTranslationalVelocity</code>, and</li>
      <li><code>CalcJacobianSpatialVelocity</code>,</li>
    </ul> each taking an argument to specify whether you'd like the Jacobian
    with respect to $\dot{q}$ or $v$.</p>

    <example><h1>Kinematic Jacobians for pick and place</h1>
    
      <p>Let's repeat the setup from above, but we'll print out the Jacobian of the gripper frame, relative to the world frame, expressed in the world frame.</p>

      <p><a target="pick"
        href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pick.ipynb#scrollTo=hSeD3PBotJUU"><img
        src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
        </p>

    </example>

  </section>

  <section><h1>Differential inverse kinematics</h1>
    
    <p>There is important structure in Eq \eqref{eq:jacobian}.  Make sure you
    didn't miss it.  The relationship between joint velocities and end-effector
    velocities is (configuration-dependent) linear: $$V^G = J^G(q)v.$$  Maybe
    this gives us what we need to produce changes in gripper frame $G$?  If I
    have a desired gripper frame velocity $V^{G_d}$, then how about commanding a
    joint velocity $v = [J^G(q)]^{-1} V^{G_d}$?</p>

    <subsection><h1>The Jacobian pseudo-inverse</h1>

      <p>Any time you write a matrix inverse, it's important to check that the
      matrix is actually invertible.  As a first sanity check: what are the
      dimensions of $J^G(q)$?  We know the spatial velocity has six elements.
      Our gripper frame is welded directly on the last link of the iiwa, and the
      iiwa has seven positions, so we have $J^G(q_{iiwa}) \in \Re^{6x7}.$  The
      matrix is not square, so does not have an inverse.  But having <i>more</i>
      degrees of freedom than the desired spatial velocity requires (more
      columns than rows) is actually the good case, in the sense that we might
      have many solutions for $v$ that can achieve a desired spatial velocity.
      To choose one of them (the minimum-norm solution), we can consider using
      the <a
      href="https://en.wikipedia.org/wiki/Moore%E2%80%93Penrose_inverse">Moore-Penrose
      pseudo-inverse</a>, $J^+$, instead: $$v = [J^G(q)]^+V^{G_d}.$$</p>

      <p>The pseudo-inverse is a beautiful mathematical concept.  When the $J$
      is square and full-rank, the pseudo-inverse returns the true inverse of
      the system. When there are many solutions (here many joint velocities that
      accomplish the same end-effector spatial velocity), then it returns the
      minimum-norm solution (the joint velocities that produce the desired
      spatial velocity which are closest to zero in the least-squares sense).
      When there is no exact solution, it returns the joint velocities that
      produce an spatial velocity which is as close to the desired end-effector
      velocity as possible, again in the least-squares sense.  So good!</p>

      <example><h1>Our first end-effector "controller"</h1>
      
        <p>Let's write a a simple controller using the pseudo-inverse of the
        Jacobian.  First, we'll write a new <code>LeafSystem</code> that defines
        one input port (for the iiwa measured position), and one output port
        (for the iiwa joint velocity command).  Inside that system, we'll ask
        MultibodyPlant for the gripper Jacobian, and compute the joint
        velocities that will implement a desired gripper spatial velocity.</p>

        <p>To keep things simple for this first example, we'll just command a
        constant gripper spatial velocity, and only run the simulation for a few
        seconds.</p>

        <p>Note that we do have to add one additional system into the diagram.
        The output of our controller is a desired joint velocity, but the input
        that the iiwa controller is expecting is a desired joint position.  So
        we will insert an integrator inbetween.</p>

        <p>I don't expect you to understand every line in this example, but it's
        worth finding the important lines and making sure you can change them
        and see what happens!</p>

        <p><a target="pick"
          href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pick.ipynb#scrollTo=6v-EGfoI3y6V"><img
          src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
          </p>
  
        <p>Congratulations!  Things are really moving now.</p>

      </example>

    </subsection>

    <subsection><h1>Invertibility of the Jacobian</h1>

      <p>There is a simple check to understand when the pseudo-inverse can give
      an exact solution (achieving exactly the desired spatial velocity): the
      Jacobian must be full <i>row</i>-rank.  In this case, we need $\rank(J) =
      6$. But assigning an integer rank to a matrix doesn't tell the entire
      story; for a real robot with (noisy) floating-point joint positions, as
      the matrix gets <i>close</i> to losing rank, (pseudo-)inverse starts to
      "blow-up".  A better metric, then, is to watch the smallest singular
      value; as this approaches zero, the norm of the pseudo-inverse will
      approach infinity.</p>

      <example><h1>Invertibility of the gripper Jacobian</h1>
      
        <p>You might have noticed that I printed out the smallest singular value
        of $J^G$ in one of the previous examples.  Take it for another spin.
        See if you can find configurations where the smallest singular value
        gets close to zero.</p>

        <p><a target="pick"
          href="https://colab.research.google.com/github/RussTedrake/manipulation/blob/master/pick.ipynb#scrollTo=hSeD3PBotJUU"><img
          src="https://colab.research.google.com/assets/colab-badge.svg" alt="Open In Colab"/></a>
          </p>

        <p>Here's a hint: try some configurations where the arm is very
        straight, (e.g. driving joint 2 and 4 close to zero).</p>

        <p>Another good way to find the singularities are to use your
        pseudo-inverse controller to send gripper spatial velocity commands that
        drive the gripper to the limits of the robot's workspace.  Try it and
        see!  In fact, this is the common case, and one that we want to work
        hard to avoid.</p>

      </example>

      <p>Configurations $q$ for which $\rank(J(q_{iiwa})) < 6$ for a frame of
      interest (like our gripper frame $G$) are called <i>kinematic
      singularities</i>.  Try to avoid them if you can!  The iiwa has many
      virtues, but admittedly its kinematic workspace is not one of them. Trust
      me, if you try to get a big Kuka to reach into a little kitchen sink all
      day, every day, then you will spend a non-trivial amount of time thinking
      about avoiding singularities.</p>

      <p>In practice, things can get a lot better if we stop bolting our robot
      base to a fixed location in the world.  Mobile bases add complexity, but
      they are wonderful for improving the kinematic workspace of a robot.</p>

    </subsection>

    <subsection><h1>Nullspace of the Jacobian</h1>
    
      <p>I've already mentioned a very nice and important property of the
      pseudo-inverse: in the case where there are multiple solutions, it will
      return the minimum-norm solution.  Since we have seven joints to control a
      six element spatial velocity, as long as we are away from kinematic
      singularties, this means effectively that there is some subspace (in this
      example it will have dimension at most one) in which the pseudo-inverse
      effectively sets the velocity to zero.</p>

      <p>Perhaps that's what we want.  But now that I've admitted my fear of
      singularities, let me propose a different option.  What if we take that
      subspace, which instantaneously has nothing to do with the task, and use
      it to move the robot back towards a comfortable joint position far away
      from singularities?</p>

      <p>Nullspace</p>

      <example><h1>Nullspace centering</h1>

        <todo>Add centering to the jacobian controller.</todo>
      </example>

      <p>This is just one example of how we can use the nullspace to produce a
      sort of hierarchy of controllers.  The payoff is modest on our seven DOF
      robot, but it can become substantial when you are commanding an entire
      humanoid, or perhaps even a dexterous hand.</p>

    </subsection>
  </section>

  <section><h1>Defining the grasp and pre-grasp poses</h1>
  
  <p><i>TODO: snapshot of the gripper relative to the object.  Back out a reasonable grasp pose (gripper position = object + some z, orientation straight down).  Pre-grasp pose is +more z. </i></p>
  
  </section>

  <section><h1>A pick and place trajectory</h1></section>

  <section><h1>Differential inverse kinematics with constraints</h1>

    <p>We had to move very slowly in the example above.  </p>

    <subsection><h1>Pseudo-inverse as an optimization</h1>
    
    </subsection>

    <todo>Find a home for inverse kinematics, including nonlinear optimization
    and closed-form solutions (e.g. IK-fast)</todo>

  </section>

  <section><h1>A simpler pick and place trajectory</h1></section>

  <section><h1>Putting it all together</h1></section>

</chapter>
<!-- EVERYTHING BELOW THIS LINE IS OVERWRITTEN BY THE INSTALL SCRIPT -->

<table style="width:100%;"><tr style="width:100%">
  <td style="width:33%;text-align:left;"><a class="previous_chapter" href=robot.html>Previous Chapter</a></td>
  <td style="width:33%;text-align:center;"><a href=index.html>Table of contents</a></td>
  <td style="width:33%;text-align:right;"><a class="next_chapter" href=pixels.html>Next Chapter</a></td>
</tr></table>

<div id="footer">
  <hr>
  <table style="width:100%;">
    <tr><td><em>Robotic Manipulation</em></td><td style="text-align:right">&copy; Russ
      Tedrake, 2020</td></tr>
  </table>
</div>


</body>
</html>
